{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Face recognition\n",
    "------\n",
    "## Requeriments of face regnition systems\n",
    "\n",
    "- Speed\n",
    "- Scalability\n",
    "- High accuracy with small data\n",
    "- One-shot learning\n",
    "\n",
    "------\n",
    "\n",
    "## Naive one-shot prediction - Euclidean distance between two vectors\n",
    "\n",
    "Given the true image and a test image, one naive approach for a one-shot prediction is to simply measure the difference between the two images. All images are simply three dimensional vectors. We know that the Euclidean distance provides a mathematical formulation of the difference between two vectors. \n",
    "\n",
    "![example euclidan](https://i.imgur.com/BEzBqWs.png)\n",
    "\n",
    "\n",
    "Although the Euclidean distance for facial recognition makes sense on paper, it has a poor practical value. In reality, photos can be different due to variations in angles and lighting, and also changes in the appearance of the subject, which can arise due to the wearing of accessories such as glasses. As you can imagine, a facial recognition system that uses the Euclidean distance alone would perform terribly in reality.\n",
    "\n",
    "-----\n",
    "\n",
    "## Siamese neural networks\n",
    "\n",
    "Intuitively, humans recognize faces by comparing their key features. For example, humans use features such as the shape of eyes, the thickness of the eyebrows, the sizse of the nose, the overall shape of the face, and so on to recognize a person. This ability comes naturally to us, and we are seldom affected by varations in angles and lighting. For facial recognition, researchers have found that when convolutional layers are applied to human faces, they extract spatial features, such as eyes and noses. \n",
    "\n",
    "This insight forms the core of our algorithm for one-shot learning:\n",
    "\n",
    "- Use convolutional layers to extract identifying features from faces. \n",
    "- Using the euclidan distance, measure the difference of the two lower-dimension vectors output from the convolutional layers. The Euclidian distance is *inversely (?)* proportional to the simalirity between the two images\n",
    "\n",
    "Ona las thing to note is that, since we are feeding two images into our neural network simultaneously, we need to separete sets of convolutional layers. However, we require the two separete sets of convolutional layers to shape the same weights, because we wanto similar faces to be mapped to the same point in the lower-dimension feature space. \n",
    "\n",
    "We can thus think of these two sets of convolutional layers as twins, as they share the same weights. \n",
    "\n",
    "![twins](https://i.imgur.com/Px8pWP9.png)\n",
    "\n",
    "This neural network is known as a Siamese neural network, because just like a Siamese twin, it has a conjoined component at the convolutional layers.\n",
    "\n",
    "-----\n",
    "\n",
    "## Contrasstive loss\n",
    "\n",
    "This new paradigm of training a nerual network for distance-based predictions instead of classification-based preditions requires a new loss fuction. \n",
    "\n",
    "We require a new distance-based loss function to train our Siamese neural network for facial recognition. The distance based loss function that we will be using is called the contrastove loss function.\n",
    "\n",
    "Take a look at the following variables:\n",
    "\n",
    "- **$ Y_{true} $** Let $ Y_{true} $ be 1 if the two input images are from the same subject (same face), and 0 if the two input images are from different subjects.\n",
    "- **$ D $** The predicted distance output from the neural network\n",
    "\n",
    "So, the contrastive loss is defined as follows:\n",
    "\n",
    "$$\n",
    "\\textrm{Contrastive Loss} = Y_{true} \\ast D^2 + ( 1-Y_{true}) \\ast \\textrm{max} ( \\textrm{margin} - D, 0)\n",
    "$$\n",
    "\n",
    "The following graph  shows the loss for the increasing predicted distance, when the faces are similar (left) and when the faces are different (right)\n",
    "\n",
    "![graph](https://i.imgur.com/N0pZbXQ.png)\n",
    "\n",
    "Simply put, the constrastive loss function ensures that our siamese neural network learns to predict a small distance when the faces in the true and test images are the same, and a large distance when the faces is the true and test images are differnt.\n",
    "\n",
    "------\n",
    "\n",
    "# The faces dataset\n",
    "\n",
    "The dataset that we have chosen is the Database of Faces, created by AT&T Laboratories, Cambridge.  The database contains photos of 40 subjects, with 10 photos for each subject. The photos of each subject were taken under different lighting and angles, and they have different facial expressions. For certain subjects, multiple photos were taken of people with and without glasses\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
