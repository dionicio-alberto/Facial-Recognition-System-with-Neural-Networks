{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition System with Neural Networks\n",
    "\n",
    "We will implement a facial recognition system using a **Siamese neural network**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Facil recognition systems\n",
    "\n",
    "FAcial recognition systems have become ubiquitous in our every lives. When the iPhone X was first unveiledin 2017, Apple boasted that their new state-of-the-art face ID system was able to instantaneously recognize and authenticate users with just a single glance. Today, almost all smartphones have a facial recognition security system. \n",
    "\n",
    "------\n",
    "## Breaking down the face recognition problem\n",
    "\n",
    "A face recognition problem can be broken down into the following smaller subproblems:\n",
    "\n",
    "- **Face detection**: Detect and isolate faces in the image. In an image with multiple face, we need to detect each of them separately. \n",
    "- **Face recognition**: For each detected face in the image, we run it through a neural network to classify the subject. \n",
    "\n",
    "![diagram](https://i.imgur.com/ZwhaYns.png)\n",
    "\n",
    "-----\n",
    "\n",
    "# Face detection\n",
    "\n",
    "The face detection problem is actually a rather interesting problem in computer vision that researchers have worked on for many years. Today, face detection algorithms can be run on simple hardware such as our personal computers with just a few lines of code. \n",
    "\n",
    "There are several approaches to face detection:\n",
    "\n",
    "- Haar Cascades\n",
    "- Eigenfaces\n",
    "- Histogram of Oriented Gradients (HOG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Haar Cascades\n",
    "\n",
    "We'll explain how to do face detection using Haar Cascades(as presented by Viola and Jones in 2001)\n",
    "\n",
    "The key idea behindthe Viola-Jones algorithm is that all human faces share certain properties, such as the following:\n",
    "\n",
    "- The area of the eye is darker than the forehead and the cheeks\n",
    "- The area of the nose is brighter than the eyes\n",
    "\n",
    "In a frontal, non-occluded image of a human face, we can see features such as the eyes, the nose, and the lips. If we look closely at the area around the eyes, we see that there is a repeating patter of dark and light pixels\n",
    "\n",
    "![diagram2](https://i.imgur.com/61TpWY2.png)\n",
    "\n",
    "We can also construct other features that capture other regions of the face, such aas the nose, lips, chin, and so on. Some examples of other features are shown in the following diagram:\n",
    "\n",
    "![DIAGRAM3](https://i.imgur.com/6tbVGTA.png)\n",
    "\n",
    "These features with alternating regions of dark and light pixels are known as Haar features. In the final algorithm presented by Viola and Jones, there were more than 6000 Haar features used.\n",
    "\n",
    "To use the Haar feactures, we slide them over every region in the image and compute the similarity of the pixels with the Haar features. Viola and Jones introduced a cascade classifier. The idea is to start with the most simple Haar feature. If the candidate region fails, this simple Haar feature,we immediately move on to the next candidate region. This way, we do not waste computational resources on reginons that do not contain face. We progressively move on the more complex Haar features, and we repeat the process. Eventually, the regions in the image with a face are the regions that pass all the Haar features. This classifier is known as a cacade classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "CURRENT_DIR = Path('.').resolve()\n",
    "MODULES_DIR = CURRENT_DIR.parent.joinpath('src')\n",
    "sys.path.append(str(MODULES_DIR))\n",
    "DATA_DIR = CURRENT_DIR.parent.joinpath('Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Face detection in Python\n",
    "\n",
    "Face detecion can be implemented by the OpenCV library in Python. OpenCV is an open source computer vision librery for computer vision task. \n",
    "\n",
    "First, we import OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a pre-trained cascade classifier for face detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascades = cv2.CascadeClassifier(str(CURRENT_DIR.parent.joinpath(\n",
    "    'models','haarcascade_frontalface_default.xml'\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that takes in an image, performs face detection on the image, and draws a bounding box aurond the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img, draw_box = True):\n",
    "    # Convert image to grayscale\n",
    "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = face_cascades.detectMultiScale(grayscale_img, scaleFactor=1.6)\n",
    "    \n",
    "    # Draw bounding box around detected faces\n",
    "    for (x,y, width, height) in faces:\n",
    "        if draw_box:\n",
    "            cv2.rectangle(img, (x,y), (x+width, y+height),(0, 255,0),5)\n",
    "        face_box = img[y:y+height, x:x+width]\n",
    "        face_coords = [x,y,width,height]\n",
    "        return img, face_box, face_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the `detect_faces` function that we defined earlier on these images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for archivo in DATA_DIR.joinpath('Sample Faces').rglob('*.jpg'):\n",
    "    files.append(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/dionicio/Documents/Redes Neuronales/Facial-Recognition/Data/Sample Faces/img1.jpg'),\n",
       " PosixPath('/home/dionicio/Documents/Redes Neuronales/Facial-Recognition/Data/Sample Faces/img4.jpg'),\n",
       " PosixPath('/home/dionicio/Documents/Redes Neuronales/Facial-Recognition/Data/Sample Faces/img3.jpg'),\n",
       " PosixPath('/home/dionicio/Documents/Redes Neuronales/Facial-Recognition/Data/Sample Faces/img2.jpg')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in files:\n",
    "    img = cv2.imread(str(image))\n",
    "    detected_faces, _, _ = detect_faces(img)\n",
    "    cv2.imwrite(str(DATA_DIR.joinpath('Detected',str(image)[-8:])),detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "![Resultado](https://i.imgur.com/4dWUUJn.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
